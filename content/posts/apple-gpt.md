---
author: "Ben Tranter"
title: "Apple GPT"
date: "2023-07-19"
description: "The commoditization of LLMs"
---

Today, $AAPL spiked 2% around mid-day, apparently on the news that Apple is [working on its own GPT-like product](https://www.bloomberg.com/news/articles/2023-07-19/apple-preps-ajax-generative-ai-apple-gpt-to-rival-openai-and-google). Apple creating a GPT product that runs on a Cloud provider is cool and all, but I think they can do better.

**I think they can (and will) commoditize OpenAI's entire product.**

If (or maybe I should say when) Apple figures out how to run a model competitive with GPT-4 on customers' devices, they distribute the computational expense. If everyone owns a device that runs a competitive model locally, why would anyone ever pay the price (both in money and in network latency) to access a centralized model?

Apple can expose this through a Swift SDK for native apps, and JS SDK for web apps. Once they succeed in this, everyone will follow â€“ Google with Android, Meta with their ecosystem, even Salesforce with their platform. Developers will adopt this new approach, and the ecosystem will change almost immediately. What will OpenAI do after that?
